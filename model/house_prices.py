# -*- coding: utf-8 -*-
"""House Prices

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1do1hxOiSPGDXfgshGXmVeQtU-6vUM0Ae
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
# %matplotlib inline
import matplotlib
matplotlib.rcParams["figure.figsize"] = (20,10)

#import os
#print(os.getcwd())
#defining the data frame and showing it content
df1 = pd.read_csv("IndiaData.csv")
df1.head()

#showing the number of rows and colmns
df1.shape

# counting number of rows of each area type.
df1.groupby('area_type')['area_type'].agg('count')

#dropping unneccesary colmns
df1 = pd.read_csv("IndiaData.csv")
df2 = df1.drop(['area_type','society','balcony','availability'],axis ='columns')
df2.head()

#showing the number of empty rows in each colmn
df2.isnull().sum()

#dropping all the empty rows
df3 = df2.dropna()
df3.isnull().sum()

df3.shape

#showing unique values in "size" colmn
df3['size'].unique()

# Create a new colmn "bhk" an fill it row values with the number in the entry of the corresponding size column
df3['bhk'] = df3['size'].apply(lambda x: int(x.split(' ')[0]))

df3.head()
#Showing all the unique entries from the total_sqft colmn
df3.total_sqft.unique()

# Creating a function to show the invalid entries
def is_float(x):
 try:
    float(x)
 except:
    return False
 return True 
df3[~df3['total_sqft'].apply(is_float)]

# converting ranges to a float number

def range_to_num(x):
  Number = x.split('-')
  if len(Number) == 2:
    return(float(Number[0])+float(Number[1]))/2
  try: 
      return float(x)
  except:
      return None

# show a dataframe with the enteries of the total_sqft colmn being float number

df3['total_sqft'] = df3['total_sqft'].apply(range_to_num)
 df3.head(3)

# feature engineering and

# converting ranges to a float number and creating a price_per_sqft colmn with it entries



df5 = df3.copy()
df5['price_per_sqft'] = df5['price']*100000/df5['total_sqft']
df5.head()

len(df5.location.unique())

"""Finding how many datapoint are there per location.

code below removes spaces before or at the end of a location text.
"""

df5.location = df5.location.apply(lambda x: x.strip())

"""group the data frame by locations. which each location, count the number of entries in the data frame. arrange the count results in desending order"""

df6 = df5
df6.head()

location_stats = df5.groupby('location')['location'].agg('count').sort_values(ascending=False)
location_stats

"""finding location with less than 10 datapoints"""

len(location_stats[location_stats<=10])

less_than_10 =location_stats[location_stats<=10]
less_than_10

df5.location = df5.location.apply(lambda x:'other' if x in less_than_10 else x)

len(df5.location.unique())

df5.head(12)

"""create a new data frame without datapoimts where the price per bhk ismore than 300."""

df6 = df5[~(df5.total_sqft/df5.bhk<300)]
df6.shape

"""find basic statistics info on agiven colmn"""

df6.price_per_sqft.describe()

"""Removing outliers (prices that are too low or too high for a particular location) using mean and standard deviation"""

def remove_outliers(df):
 df_new = pd.DataFrame()
 for key, data in df.groupby('location'):
  m  = np.mean(data.price_per_sqft)
  st = np.std(data.price_per_sqft)
  reduced_data = data[(data.price_per_sqft > (m-st)) & (data.price_per_sqft <= (m+st))]
  df_new = pd.concat([df_new,reduced_data],ignore_index=True)
 return df_new

df7 = remove_outliers(df6)
df7.shape

"""plotting a graph to show the variation 2bhk and 3bhk apartmnt in agiven location. so that we can locate 2bhk aparment that are more expensive than 3bhk house with the same total_sqft."""

def draw_graph(df,location):
  bhk2 = df[(df.location==location) & (df.bhk==2)]
  bhk3 = df[(df.location==location) & (df.bhk==3)]
  matplotlib.rcParams['figure.figsize'] = (15,10)
  plt.scatter(bhk2.total_sqft,bhk2.price,color='blue',label ='2 BHK', s=50)
  plt.scatter(bhk3.total_sqft,bhk3.price,marker = '+',color='green',label='3 BHK', s = 50)
  plt.xlabel('Total Square Feet Area')
  plt.ylabel('Price Square Feet Area')
  plt.title(location)
  plt.legend()

draw_graph(df7,'Rajaji Nagar')

"""Removing prperties where for a given location and same total_sqft, the price of an apartment with heigher number of bedrooms is lower than a bedroom with fewer bedrooms."""

def remove_bhk_outliers(df):
  excludes_indices = np.array([])
  for location, location_df in df.groupby('location'):
    bhk_stats = {}
    for bhk, bhk_df in location_df.groupby('bhk'):
        bhk_stats[bhk] = {
            'mean': np.mean(bhk_df.price_per_sqft),
            'std':  np.std(bhk_df.price_per_sqft),
            'count': bhk_df.shape[0]
        }
    for bhk, bhk_df in location_df.groupby('bhk'):
      stats = bhk_stats.get(bhk-1)
      if stats and stats['count']>5:
          excludes_indices = np.append(excludes_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)
  return df.drop(excludes_indices,axis= 'index')          
df8 = remove_bhk_outliers(df7)
df8.shape

draw_graph(df8,'Rajaji Nagar')

"""A histogram to show that the data is a normal distribution."""

import matplotlib
matplotlib.rcParams['figure.figsize'] = (20,10)
plt.hist(df8.price_per_sqft,rwidth = 0.8)
plt.xlabel("Price Per Square Feet")
plt.ylabel("Count")

"""Exploring bathroom features"""

df8.bath.unique()

df8[df8.bath>10]

"""fish out datapoints where the number of bathrooms is 2 more than number of bedroom"""

df8[df8.bath>df8.bhk+2 ]

df9 = df8[df8.bath<df8.bhk+2 ]
df9.shape

"""Drop few unnecessary feature to make the dataframe more clean for machine learning."""

df10 =df9.drop(['size','price_per_sqft'], axis= 'columns')
df10.head(10)

"""The Location colmn has to be converted to a numeric colmn using the one hot encoding method."""

dummies = pd.get_dummies(df10.location)

"""Add the dummies data frame to the main data frame"""

df11 = pd.concat([df10,dummies.drop('other',axis='columns')],axis='columns')
df11.head()

df12 = df11.drop('location', axis='columns')
df12.head()

"""Divide the dataframe into X(independent Variable) and Y(Dependent Variable) and put the in separate data frames"""

x = df12.drop('price',axis='columns')
x.head()

y = df12.price
y.head()

"""The dataset would be divided into traning and testing dataset. training for training themodel and testing to test the performance of the model."""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size= 0.2,random_state=10)

from sklearn.linear_model import LinearRegression
lr_clf = LinearRegression()
lr_clf.fit(x_train,y_train)
lr_clf.score(x_test,y_test)

"""![alt text](https://)Using K- fold crosss method to optimize the model to give a better ratio."""

from sklearn.model_selection import ShuffleSplit
  from sklearn.model_selection import cross_val_score

  cv = ShuffleSplit(n_splits=5, test_size=0.2,random_state=0)

  cross_val_score(LinearRegression(),x,y,cv=cv)

"""Using GridSearchCV to find the best model"""

from sklearn.model_selection import GridSearchCV

 from sklearn.linear_model import Lasso
 from sklearn.tree import DecisionTreeRegressor

 def Find_BestModel(x,y):
   algo = {
       'linear_regression' : {
           'model' : LinearRegression(),
           'params' : {
               'normalize' : [True,False]
           }
       },
       'Lasso' : {
           'model' : Lasso(),
           'params' : {
               'alpha': [1,2],
               'selection' : ['random','cyclic']
           }
       },
       'decision_tree' : {
           'model' : DecisionTreeRegressor(),
           'params' : {
               'criterion' : ['mse','friedman_mse'],
               'splitter' : ['best','random']
           }
       }
   } 

   score = []
   cv = ShuffleSplit(n_splits=5, test_size=0.2,random_state=0)
   for algo_name, config in algo.items():
     gs = GridSearchCV(config['model'],config['params'], cv=cv, return_train_score= False)
     gs.fit(x,y)
     score.append(
         {
             'model': algo_name,
             'best_score':gs.best_score_,
             'best_params':gs.best_params_
         }
     )

   return pd.DataFrame(score,columns=['model','best_score','best_params'])
  
Find_BestModel(x,y)

"""Predit function to predict price."""

def Predict(location,sqft,bath,bhk):
  loc_index = np.where(x.columns==location)[0][0]

  X = np.zeros(len(x.columns))
  X[0] = sqft 
  X[1] = bath
  X[2] = bhk
  if loc_index >=0:
    X[loc_index] = 1

  return lr_clf.predict([X])[0]

Predict('1st Phase JP Nagar',1000,2,2)

Predict('1st Phase JP Nagar',1000,3,4)

"""export the model into a pickle file"""

import pickle
with open('Home Prices.pickle','wb') as f:
  pickle.dump(lr_clf,f)

import json 
columns = {
    'data_columns' : [col.lower() for col in x.columns]
}
with open("columns.json","w") as f:
  f.write(json.dumps(columns))